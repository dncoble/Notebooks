{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5612c95c",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "    Vector Output of LSTMs\n",
    "    \n",
    "    Author: Daniel Coble\n",
    "    \n",
    "    Status: Finished\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fadeab",
   "metadata": {},
   "source": [
    "An LSTM's complexity is determined by it's 'units'. This is the size of the cell state and hidden states, and an LSTM cell with a larger units number is expected to recognize more complex patterns. But because the output size of the LSTM also has units size (being the hidden state), we often come into the problem that the output has a higher dimension than what we need for our purposes. In fact, often we only want a scalar returned from the LSTM. The common solution to this is to add a dense layer to the top of the model. This works fine, but I suspect a better way to extract a scalar from the vector output of an LSTM would be to simply take the first element of its output.\n",
    "\n",
    "At first this may seem like it wouldn't work, but remember that the first element of the output is related to every other element through time. What this would seem to allow would be to let the LSTM find features which are relevant but have a nonlinear relationship with the prediction (whereas with a dense top each feature must have a linear relation to the prediction).\n",
    "\n",
    "\n",
    "In this notebook, I'll train LSTM models on the same dataset used in the \"Training an LSTM\" notebook: a time series sine wave, with the label being its frequency. I'll train three models, which only vary in the top layer. The first model will be the normal dense top, the second will take only the first element, and the third takes the norm of the output vector.\n",
    "\n",
    "**TensorFlow 2.5.0 \\\n",
    "Numpy 1.19.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad04d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def generate_time_series(batch_size, n_steps, y_type = 'period'):\n",
    "    T = np.random.rand(1, batch_size, 1) * 8 + 2\n",
    "    phase = np.random.rand(1, batch_size, 1)*2*np.pi\n",
    "    A = np.random.rand(1, batch_size, 1)*9.8 + .2\n",
    "    time = np.linspace(0, n_steps, n_steps)\n",
    "    series = A * np.sin((time - phase)*2*np.pi/T)\n",
    "    series += 0.1 * (np.random.rand(1, batch_size, n_steps) - .5)\n",
    "    rtrn = np.expand_dims(np.squeeze(series.astype(np.float32)), axis=2)\n",
    "    if(y_type == 'amplitude'):\n",
    "        return rtrn, A.flatten()\n",
    "    if(y_type == 'frequency'):\n",
    "        return rtrn, 1/T.flatten()\n",
    "    if(y_type == 'next_element'):\n",
    "        return rtrn[:,:,:-1], rtrn[:,:,-1]\n",
    "    return rtrn, T.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3235c1",
   "metadata": {},
   "source": [
    "Now we can train the models for predicting frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89dfac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "219/219 [==============================] - 9s 33ms/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 2/40\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 3/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 4/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 9.0227e-04 - val_loss: 8.3383e-04\n",
      "Epoch 5/40\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 7.7823e-04 - val_loss: 6.7883e-04\n",
      "Epoch 6/40\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 6.6687e-04 - val_loss: 6.0235e-04\n",
      "Epoch 7/40\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 5.8912e-04 - val_loss: 5.4709e-04\n",
      "Epoch 8/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 5.4307e-04 - val_loss: 5.0534e-04\n",
      "Epoch 9/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 5.1833e-04 - val_loss: 5.1212e-04\n",
      "Epoch 10/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 4.7411e-04 - val_loss: 4.7036e-04\n",
      "Epoch 11/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 4.6134e-04 - val_loss: 4.3400e-04\n",
      "Epoch 12/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 4.4733e-04 - val_loss: 4.1954e-04\n",
      "Epoch 13/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 4.2805e-04 - val_loss: 3.9671e-04\n",
      "Epoch 14/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 4.0684e-04 - val_loss: 3.8513e-04\n",
      "Epoch 15/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 3.9922e-04 - val_loss: 3.7774e-04\n",
      "Epoch 16/40\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 3.8377e-04 - val_loss: 3.7516e-04\n",
      "Epoch 17/40\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 3.8609e-04 - val_loss: 4.0725e-04\n",
      "Epoch 18/40\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 3.7498e-04 - val_loss: 3.6855e-04\n",
      "Epoch 19/40\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 3.6731e-04 - val_loss: 3.6306e-04\n",
      "Epoch 20/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.6611e-04 - val_loss: 3.5490e-04\n",
      "Epoch 21/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.6355e-04 - val_loss: 3.6549e-04\n",
      "Epoch 22/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.5796e-04 - val_loss: 3.5122e-04\n",
      "Epoch 23/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.5015e-04 - val_loss: 3.3513e-04\n",
      "Epoch 24/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.4641e-04 - val_loss: 3.3671e-04\n",
      "Epoch 25/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.4469e-04 - val_loss: 3.3666e-04\n",
      "Epoch 26/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.5988e-04 - val_loss: 3.3321e-04\n",
      "Epoch 27/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.3907e-04 - val_loss: 3.4488e-04\n",
      "Epoch 28/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.3299e-04 - val_loss: 3.2422e-04\n",
      "Epoch 29/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.2998e-04 - val_loss: 3.2428e-04\n",
      "Epoch 30/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.3013e-04 - val_loss: 3.1859e-04\n",
      "Epoch 31/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.2628e-04 - val_loss: 3.1522e-04\n",
      "Epoch 32/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.2671e-04 - val_loss: 3.1665e-04\n",
      "Epoch 33/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.2179e-04 - val_loss: 3.1972e-04\n",
      "Epoch 34/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.2026e-04 - val_loss: 3.1086e-04\n",
      "Epoch 35/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.1455e-04 - val_loss: 3.1285e-04\n",
      "Epoch 36/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.1454e-04 - val_loss: 3.0967e-04\n",
      "Epoch 37/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.1064e-04 - val_loss: 3.1068e-04\n",
      "Epoch 38/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.1908e-04 - val_loss: 3.0559e-04\n",
      "Epoch 39/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.0596e-04 - val_loss: 3.0258e-04\n",
      "Epoch 40/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.0393e-04 - val_loss: 2.9517e-04\n",
      "Epoch 1/40\n",
      "219/219 [==============================] - 9s 33ms/step - loss: 0.0097 - val_loss: 0.0028\n",
      "Epoch 2/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 3/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 4/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0011 - val_loss: 8.9089e-04\n",
      "Epoch 5/40\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 8.1316e-04 - val_loss: 7.0153e-04\n",
      "Epoch 6/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 6.7650e-04 - val_loss: 6.1999e-04\n",
      "Epoch 7/40\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 6.0549e-04 - val_loss: 5.4802e-04\n",
      "Epoch 8/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 5.5259e-04 - val_loss: 5.2083e-04\n",
      "Epoch 9/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 5.1413e-04 - val_loss: 4.8855e-04\n",
      "Epoch 10/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 4.9066e-04 - val_loss: 4.7108e-04\n",
      "Epoch 11/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 4.7003e-04 - val_loss: 4.4907e-04\n",
      "Epoch 12/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 4.5927e-04 - val_loss: 4.3912e-04\n",
      "Epoch 13/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 4.4148e-04 - val_loss: 4.2469e-04\n",
      "Epoch 14/40\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 4.2777e-04 - val_loss: 4.1583e-04\n",
      "Epoch 15/40\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 4.1923e-04 - val_loss: 4.0650e-04\n",
      "Epoch 16/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 4.1053e-04 - val_loss: 3.9784e-04\n",
      "Epoch 17/40\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 4.0076e-04 - val_loss: 3.8785e-04\n",
      "Epoch 18/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.9408e-04 - val_loss: 3.8063e-04\n",
      "Epoch 19/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.8525e-04 - val_loss: 3.7457e-04\n",
      "Epoch 20/40\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 3.7757e-04 - val_loss: 3.6620e-04\n",
      "Epoch 21/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.6986e-04 - val_loss: 3.5872e-04\n",
      "Epoch 22/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.6373e-04 - val_loss: 3.5276e-04\n",
      "Epoch 23/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.5625e-04 - val_loss: 3.4512e-04\n",
      "Epoch 24/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.5020e-04 - val_loss: 3.3955e-04\n",
      "Epoch 25/40\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 3.4565e-04 - val_loss: 3.3631e-04\n",
      "Epoch 26/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.4031e-04 - val_loss: 3.3313e-04\n",
      "Epoch 27/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.3702e-04 - val_loss: 3.2836e-04\n",
      "Epoch 28/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.3269e-04 - val_loss: 3.2388e-04\n",
      "Epoch 29/40\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 3.2951e-04 - val_loss: 3.2631e-04\n",
      "Epoch 30/40\n",
      "219/219 [==============================] - 8s 34ms/step - loss: 3.2637e-04 - val_loss: 3.2037e-04\n",
      "Epoch 31/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.2260e-04 - val_loss: 3.1478e-04\n",
      "Epoch 32/40\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 3.2055e-04 - val_loss: 3.1717e-04\n",
      "Epoch 33/40\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 3.1796e-04 - val_loss: 3.1091e-04\n",
      "Epoch 34/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.1655e-04 - val_loss: 3.0703e-04\n",
      "Epoch 35/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.1269e-04 - val_loss: 3.0601e-04\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 8s 35ms/step - loss: 3.1004e-04 - val_loss: 3.0401e-04\n",
      "Epoch 37/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.0804e-04 - val_loss: 3.0139e-04\n",
      "Epoch 38/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.0714e-04 - val_loss: 3.0115e-04\n",
      "Epoch 39/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 3.0443e-04 - val_loss: 3.0167e-04\n",
      "Epoch 40/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.0205e-04 - val_loss: 2.9632e-04\n",
      "Epoch 1/40\n",
      "219/219 [==============================] - 10s 35ms/step - loss: 0.0401 - val_loss: 0.0138\n",
      "Epoch 2/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0099 - val_loss: 0.0075\n",
      "Epoch 3/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 4/40\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 5/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 6/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 7/40\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 8/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 9/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 11/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 12/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 9.3947e-04 - val_loss: 9.0172e-04\n",
      "Epoch 13/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 8.3147e-04 - val_loss: 7.7695e-04\n",
      "Epoch 14/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 7.5898e-04 - val_loss: 7.0055e-04\n",
      "Epoch 15/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 6.5199e-04 - val_loss: 6.2283e-04\n",
      "Epoch 16/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 6.0756e-04 - val_loss: 5.6334e-04\n",
      "Epoch 17/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 5.4818e-04 - val_loss: 5.1853e-04\n",
      "Epoch 18/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 5.0842e-04 - val_loss: 4.8509e-04\n",
      "Epoch 19/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 4.8056e-04 - val_loss: 4.5330e-04\n",
      "Epoch 20/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 4.5180e-04 - val_loss: 4.5392e-04\n",
      "Epoch 21/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 4.3067e-04 - val_loss: 4.1710e-04\n",
      "Epoch 22/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 4.1152e-04 - val_loss: 3.9588e-04\n",
      "Epoch 23/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.9794e-04 - val_loss: 3.8324e-04\n",
      "Epoch 24/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.9649e-04 - val_loss: 3.7108e-04\n",
      "Epoch 25/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.7565e-04 - val_loss: 3.6874e-04\n",
      "Epoch 26/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.7238e-04 - val_loss: 3.5487e-04\n",
      "Epoch 27/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.6068e-04 - val_loss: 3.4899e-04\n",
      "Epoch 28/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.5632e-04 - val_loss: 3.4560e-04\n",
      "Epoch 29/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.5295e-04 - val_loss: 3.5200e-04\n",
      "Epoch 30/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.4448e-04 - val_loss: 3.3329e-04\n",
      "Epoch 31/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.3831e-04 - val_loss: 3.3846e-04\n",
      "Epoch 32/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.3620e-04 - val_loss: 3.2638e-04\n",
      "Epoch 33/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.3027e-04 - val_loss: 3.2035e-04\n",
      "Epoch 34/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.2865e-04 - val_loss: 3.1720e-04\n",
      "Epoch 35/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.2542e-04 - val_loss: 3.2069e-04\n",
      "Epoch 36/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.2049e-04 - val_loss: 3.1088e-04\n",
      "Epoch 37/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.1712e-04 - val_loss: 3.0718e-04\n",
      "Epoch 38/40\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 3.1354e-04 - val_loss: 3.0690e-04\n",
      "Epoch 39/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.1055e-04 - val_loss: 3.0420e-04\n",
      "Epoch 40/40\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 3.0721e-04 - val_loss: 3.0103e-04\n"
     ]
    }
   ],
   "source": [
    "# make the models. 2 LSTM layers with 15 units then changing the top. For the first element and norm models, a dense layer \n",
    "# used just to scale the result and add a bias (one weight, one bias)\n",
    "dense_top_model = keras.Sequential((\n",
    "    keras.layers.LSTM(15, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(15, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "))\n",
    "first_element_model = keras.Sequential((\n",
    "    keras.layers.LSTM(15, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(15, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Lambda(keras.layers.Lambda(lambda x: x[:,0:1]))),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "))\n",
    "norm_vector_model = keras.Sequential((\n",
    "    keras.layers.LSTM(15, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(15, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Lambda(lambda x: tf.expand_dims(tf.norm(x, axis=1), axis=1))),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "))\n",
    "\n",
    "models = [dense_top_model, first_element_model, norm_vector_model]\n",
    "\n",
    "freq_rmse = [0,0,0] # this will fill with RMSE for each model type\n",
    "freq_val = [] # append validation losses to this list\n",
    "np.random.seed(42)\n",
    "n_steps = 75\n",
    "X, y = generate_time_series(10000, n_steps + 1, y_type='frequency')\n",
    "X_train = X[:7000]; y_train = y[:7000]\n",
    "X_test = X[7000:]; y_test = y[7000:]\n",
    "\n",
    "for i in range(3):\n",
    "    model = models[i]\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=\"adam\",\n",
    "    )\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40)\n",
    "    freq_val.append(hist.history['val_loss'])\n",
    "    \n",
    "    pred = model.predict(X_test)[:,-1].flatten()\n",
    "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "    freq_rmse[i] = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a09ec8",
   "metadata": {},
   "source": [
    "Validation error plots during training for the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269ce238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss of dense top model: 0.00029517157236114144\n",
      "Final loss of first element model: 0.00029632309451699257\n",
      "Final loss of norm vector model: 0.00030103028984740376\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(freq_val[0], label=\"Dense top model\")\n",
    "plt.plot(freq_val[1], label=\"First element model\")\n",
    "plt.plot(freq_val[2], label=\"Norm vector model\")\n",
    "plt.legend()\n",
    "plt.ylim((0, .008))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Final loss of dense top model: \" + str(freq_val[0][-1]))\n",
    "print(\"Final loss of first element model: \" + str(freq_val[1][-1]))\n",
    "print(\"Final loss of norm vector model: \" + str(freq_val[2][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c91458",
   "metadata": {},
   "source": [
    "Despite having different convergence rates, the final error of all three models are roughly the same. Therefore it does not seem like the the first element model is more inclined to detect more complex patterns. Also, surprisingly, despite starting with a much higher error, the norm vector model converged to a similar value. I expected that the norm vector model would perform worse, as the model would loose resolution when predicting small values.\n",
    "\n",
    "Ignoring the modest decrease in the amount of weights, there seems to be little reason to implement first element models. I still like the idea however, because it seems more elegant than the 'hacky' solution of a top layer dense/convolutional cell.\n",
    "\n",
    "A more thorough analysis of this idea would include varying the sizes of the LSTM cells. Datasets which include time series prediction or other uses of LSTMs could be used. I suspect that norm vector models would perform poorly in datasets which includes labels close to zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

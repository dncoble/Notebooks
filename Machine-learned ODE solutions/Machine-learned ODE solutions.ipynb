{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce7456ef",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "    Machine-learned ODE solutions\n",
    "    \n",
    "    Author: Daniel Coble\n",
    "    \n",
    "    Status: Work in progress\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152ea1a",
   "metadata": {},
   "source": [
    "This notebook is substantially similar to the one published [here](https://github.com/ARTS-Laboratory), and covers the same material as an extended abstract published to IMAC. In effect, we reproduce and explain the methodology explored by QiuYu Chen in his [Master's Thesis](https://repository.lib.ncsu.edu/handle/1840.20/37410). To do this, autograd is used to calculate all ODE derivatives and the gradient of the error function. Consider the standard formulation fo the ODE representation of free vibration on a string.\n",
    "$$ \\frac{\\partial^2w}{\\partial x^2} + \\lambda\\frac{\\partial^2w}{\\partial t^2}=0$$\n",
    "$$ w(x, t=0)=g_1(x), \\left.\\frac{\\partial w(x)}{\\partial t}\\right|_{t=0} = g_2(x), w(x=0, 1, t)=0$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd063d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\"\"\"\n",
    "tensorflow/keras classes for physics-informed machine learning\n",
    "\"\"\"\n",
    "#%% compute at interior, initial, and boundary\n",
    "# needed for dispatching\n",
    "class GradientLayer(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "               trainable=True,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               dynamic=False,\n",
    "               **kwargs):\n",
    "        super().__init__(trainable=True,\n",
    "                       name=None,\n",
    "                       dtype=None,\n",
    "                       dynamic=False,\n",
    "                       **kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        y = inputs[0]\n",
    "        x = inputs[1]\n",
    "        return tf.gradients(y, x)[0]\n",
    "\n",
    "class ModelInterior(keras.layers.Layer):\n",
    "    \n",
    "    '''\n",
    "    wraps model and computes for interior\n",
    "    '''\n",
    "    def __init__(self, model,\n",
    "               trainable=True,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               dynamic=False,\n",
    "               **kwargs):\n",
    "        self.model = model\n",
    "        super().__init__(trainable=True,\n",
    "                       name=None,\n",
    "                       dtype=None,\n",
    "                       dynamic=False,\n",
    "                       **kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        t = inputs[1]\n",
    "        xt = tf.concat([x, t], -1)\n",
    "        return self.model(xt)\n",
    "        \n",
    "class ModelInitial(keras.layers.Layer):\n",
    "    '''\n",
    "    wraps model and computes for only t=0\n",
    "    '''\n",
    "    def __init__(self, model, \n",
    "                 trainable=True,\n",
    "                 name=None,\n",
    "                 dtype=None,\n",
    "                 dynamic=False,\n",
    "                 **kwargs):\n",
    "        self.model = model\n",
    "        super().__init__(trainable=True,\n",
    "                       name=None,\n",
    "                       dtype=None,\n",
    "                       dynamic=False,\n",
    "                       **kwargs)\n",
    "    \n",
    "    '''\n",
    "    returns also t (needed for gradient calculation downstream)\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        t = tf.zeros(x.shape)\n",
    "        xt = tf.concat([x, t], -1)\n",
    "        \n",
    "        return [self.model(xt), t]\n",
    "\n",
    "class ModelBoundary(keras.layers.Layer):\n",
    "    '''\n",
    "    wraps model and computes for x=0, x=1\n",
    "    '''\n",
    "    def __init__(self, model,\n",
    "                 trainable=True,\n",
    "                 name=None,\n",
    "                 dtype=None,\n",
    "                 dynamic=False,\n",
    "                 **kwargs):\n",
    "        self.model = model\n",
    "        super().__init__(trainable=True,\n",
    "                       name=None,\n",
    "                       dtype=None,\n",
    "                       dynamic=False,\n",
    "                       **kwargs)\n",
    "    \n",
    "    '''\n",
    "    returns at x=0 and x=1\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        t = inputs\n",
    "        x0 = tf.zeros(t.shape)\n",
    "        x1 = tf.ones(t.shape)\n",
    "        x0t = tf.concat([x0, t], -1)\n",
    "        x1t = tf.concat([x1, t], -1)\n",
    "        \n",
    "        w0 = self.model(x0t)\n",
    "        w1 = self.model(x1t)\n",
    "        \n",
    "        return [w0, w1]\n",
    "\n",
    "#%% losses\n",
    "class WaveLoss(keras.layers.Layer):\n",
    "    '''\n",
    "    x: tensor reference to displacement input\n",
    "    t: tensor reference to time input\n",
    "    rhof: weight of interior \n",
    "    '''\n",
    "    def __init__(self, x, t, lam,\n",
    "                 trainable=True,\n",
    "                 name=None,\n",
    "                 dtype=None,\n",
    "                 dynamic=False,\n",
    "                 **kwargs):\n",
    "        self.lam = np.array([lam], dtype=np.float32)\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        super().__init__(trainable=True,\n",
    "                       name=None,\n",
    "                       dtype=None,\n",
    "                       dynamic=False,\n",
    "                       **kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # self.input_shape = input_shape # should be [None, 2]\n",
    "        # make lam a tf variable\n",
    "        self.lam = tf.Variable(initial_value=self.lam, trainable=False)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        w = inputs\n",
    "        dwdx = GradientLayer()([w, self.x])\n",
    "        d2wdx2 = GradientLayer()([dwdx, self.x])\n",
    "        dwdt = GradientLayer()([w, self.t])\n",
    "        d2wdt2 = GradientLayer()([dwdt, self.t])\n",
    "        \n",
    "        return self.lam*d2wdx2 - d2wdt2\n",
    "\n",
    "class InitialLoss(keras.layers.Layer):\n",
    "    '''\n",
    "    g1: tf function for initial displacement\n",
    "    g2: tf function for initial velocity\n",
    "    t: tf tensor for time input\n",
    "    '''\n",
    "    def __init__(self, g1, g2,\n",
    "                 trainable=True,\n",
    "                 name=None,\n",
    "                 dtype=None,\n",
    "                 dynamic=False,\n",
    "                 **kwargs):\n",
    "        self.g1 = g1\n",
    "        self.g2 = g2\n",
    "        super().__init__(trainable=True,\n",
    "                       name=None,\n",
    "                       dtype=None,\n",
    "                       dynamic=False,\n",
    "                       **kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        w, x, t = inputs\n",
    "        dwdt = tf.gradients(w, t)\n",
    "        g1x = self.g1(x)\n",
    "        g2x = self.g2(x)\n",
    "        \n",
    "        return tf.square(w - g1x) + tf.square(dwdt - g2x)\n",
    "    \n",
    "class BoundaryLoss(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 trainable=True,\n",
    "                 name=None,\n",
    "                 dtype=None,\n",
    "                 dynamic=False,\n",
    "                 **kwargs):\n",
    "        super().__init__(trainable=True,\n",
    "                       name=None,\n",
    "                       dtype=None,\n",
    "                       dynamic=False,\n",
    "                       **kwargs)\n",
    "    '''\n",
    "    boundary values should always be zero, no constraint on derivatives\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        w0 = inputs[0]\n",
    "        w1 = inputs[1]\n",
    "        \n",
    "        return tf.square(w0) + tf.square(w1)\n",
    "\n",
    "class WeightSum(keras.layers.Layer):\n",
    "    '''\n",
    "    pass weights\n",
    "    '''\n",
    "    def __init__(self, *args,\n",
    "                 trainable=True,\n",
    "                 name=None,\n",
    "                 dtype=None,\n",
    "                 dynamic=False,\n",
    "                 **kwargs):\n",
    "        self.args = args\n",
    "        super().__init__(trainable=True,\n",
    "                       name=None,\n",
    "                       dtype=None,\n",
    "                       dynamic=False,\n",
    "                       **kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        rtrn = inputs[0]*self.args[0]\n",
    "        for arg, inp in zip(self.args[1:], inputs[1:]):\n",
    "            rtrn += tf.reduce_mean(inp)*arg\n",
    "        return rtrn\n",
    "\n",
    "'''\n",
    "If you're using this function you're doing something wrong\n",
    "'''\n",
    "class IdentityLoss(keras.losses.Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0c56d",
   "metadata": {},
   "source": [
    "Describe system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f30694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical constants\n",
    "T = 1\n",
    "L = 1\n",
    "lam = 1\n",
    "# g1 - initial position\n",
    "@tf.function\n",
    "def g1(x):\n",
    "    M = 1/(2*np.pi)\n",
    "    return .1*tf.math.sin(M*x)\n",
    "# g2 - initial velocity\n",
    "@tf.function\n",
    "def g2(x):\n",
    "    return tf.zeros(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d5f30",
   "metadata": {},
   "source": [
    "Training constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d69a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhof = 1\n",
    "rho0 = .2\n",
    "rhob = .2\n",
    "batch_size = 64\n",
    "# number of points at initial, boundary, and interior during each epoch. Each must be a multiple of the batch size. \n",
    "Nf = 4096 # number of interior points\n",
    "N0 = 4096 # number of initial points\n",
    "Nb = 4096 # number of boundary points\n",
    "num_epochs = 200\n",
    "learning_rate=.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af5eb57",
   "metadata": {},
   "source": [
    "Go about creating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f232aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "# dense approximating NN\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='sigmoid', use_bias=True, trainable=True),\n",
    "    keras.layers.Dense(30, activation='sigmoid', use_bias=True, trainable=True),\n",
    "    keras.layers.Dense(1, activation='sigmoid', use_bias=True, trainable=True),\n",
    "])\n",
    "\n",
    "# build computation graph\n",
    "x_interior = keras.layers.Input(batch_input_shape=[64, 1], name='x_interior')\n",
    "t_interior = keras.layers.Input(batch_input_shape=[64, 1], name='t_interior')\n",
    "# initial and boundary inputs\n",
    "x_initial = keras.layers.Input(batch_input_shape=[64, 1], name='x_initial')\n",
    "t_boundary = keras.layers.Input(batch_input_shape=[64, 1], name='t_boundary')\n",
    "\n",
    "model_interior = ModelInterior(model)([x_interior, t_interior])\n",
    "model_initial, t_initial = ModelInitial(model)(x_initial)\n",
    "model_boundary = ModelBoundary(model)(t_boundary)\n",
    "\n",
    "# wave layer enforcing differential equation\n",
    "wave_loss = WaveLoss(x_interior, t_interior, lam)(model_interior)\n",
    "# enforcing initial conditions\n",
    "initial_loss = InitialLoss(g1, g2)([model_initial, x_initial, t_initial])\n",
    "# enforcing boundary conditions\n",
    "boundary_loss = BoundaryLoss()(model_boundary)\n",
    "#total loss\n",
    "loss = WeightSum(rhof, rho0, rhob)([wave_loss, initial_loss, boundary_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410a256a",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6491c797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'x_initial' with dtype float and shape [64,1]\n\t [[{{node x_initial}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# gradient of loss w.r.t. approximating function weights\u001b[39;00m\n\u001b[0;32m      2\u001b[0m grads \u001b[38;5;241m=\u001b[39m GradientLayer()([loss, model\u001b[38;5;241m.\u001b[39mweights])\n\u001b[1;32m----> 3\u001b[0m training_model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mx_interior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_interior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_boundary\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# keep results for plotting\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\keras\\src\\engine\\functional.py:167\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    159\u001b[0m         [\n\u001b[0;32m    160\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    162\u001b[0m         ]\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\keras\\src\\engine\\functional.py:207\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_history\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs\n\u001b[0;32m    206\u001b[0m     ):\n\u001b[1;32m--> 207\u001b[0m         \u001b[43mbase_layer_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_keras_history\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nested_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_graph_inputs_and_outputs()\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# A Network does not create weights of its own, thus it is already\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# built.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:211\u001b[0m, in \u001b[0;36mcreate_keras_history\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_keras_history\u001b[39m(tensors):\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wraps TensorFlow Operations for compatibility with the Functional API.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    This method checks to see if a Tensor in `tensors` is missing Keras metadata\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m        the raw Tensorflow operations.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m     _, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_create_keras_history_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m created_layers\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:297\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 constants[i] \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfunction([], op_input)([])\n\u001b[0;32m    296\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[1;32m--> 297\u001b[0m processed_ops, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_create_keras_history_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreated_layers\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m name \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    301\u001b[0m node_def \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mnode_def\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:297\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 constants[i] \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfunction([], op_input)([])\n\u001b[0;32m    296\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[1;32m--> 297\u001b[0m processed_ops, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_create_keras_history_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreated_layers\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m name \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    301\u001b[0m node_def \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mnode_def\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "    \u001b[1;31m[... skipping similar frames: _create_keras_history_helper at line 297 (4 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:297\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 constants[i] \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfunction([], op_input)([])\n\u001b[0;32m    296\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[1;32m--> 297\u001b[0m processed_ops, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_create_keras_history_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreated_layers\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m name \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    301\u001b[0m node_def \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mnode_def\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:295\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[1;32m--> 295\u001b[0m                 constants[i] \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[0;32m    297\u001b[0m processed_ops, created_layers \u001b[38;5;241m=\u001b[39m _create_keras_history_helper(\n\u001b[0;32m    298\u001b[0m     layer_inputs, processed_ops, created_layers\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\keras\\src\\backend.py:4609\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4601\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4605\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4606\u001b[0m ):\n\u001b[0;32m   4607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4609\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[0;32m   4611\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4612\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4613\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4614\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4615\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-213\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1482\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1481\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1482\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1485\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1486\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'x_initial' with dtype float and shape [64,1]\n\t [[{{node x_initial}}]]"
     ]
    }
   ],
   "source": [
    "# gradient of loss w.r.t. approximating function weights\n",
    "grads = GradientLayer()([loss, model.weights])\n",
    "training_model = keras.Model(\n",
    "    inputs=[x_interior, t_interior, x_initial, t_boundary],\n",
    "    outputs=[loss, grads]\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    # create stochastic training points\n",
    "    x_int = np.random.rand(Nf)\n",
    "    t_int = np.random.rand(Nf)\n",
    "    x_init = np.random.rand(N0)\n",
    "    t_bound = np.random.rand(Nb)\n",
    "    \n",
    "    x_int = x_int.reshape(-1, batch_size, 1)\n",
    "    t_int = t_int.reshape(-1, batch_size, 1)\n",
    "    x_init = x_init.reshape(-1, batch_size, 1)\n",
    "    t_bound = t_bound.reshape(-1, batch_size, 1)\n",
    "    \n",
    "    for x_int1, t_int1, x_init1, t_bound1 in zip(x_int, t_int, x_init, t_bound):\n",
    "        # Optimize the model\n",
    "        loss_value, grads = training_model(x_int, t_int, x_init, t_bound)\n",
    "        optimizer.apply_gradients(zip(grads, training_model.trainable_variables))\n",
    "        \n",
    "        # Track progress\n",
    "        epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "        \n",
    "        # End epoch\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "    \n",
    "    if(epoch % 1 == 0):\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadfc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Dense(30, activation='sigmoid', use_bias=True, trainable=True),\n",
    "#     keras.layers.Dense(30, activation='sigmoid', use_bias=True, trainable=True),\n",
    "#     keras.layers.Dense(1, activation='sigmoid', use_bias=True, trainable=True),\n",
    "# ])\n",
    "\n",
    "# # build computation graph\n",
    "# x_interior = keras.layers.Input(batch_input_shape=[64, 1], name='x_interior')\n",
    "# t_interior = keras.layers.Input(batch_input_shape=[64, 1], name='t_interior')\n",
    "# # initial and boundary inputs\n",
    "# x_initial = keras.layers.Input(batch_input_shape=[64, 1], name='x_inital')\n",
    "# t_boundary = keras.layers.Input(batch_input_shape=[64, 1], name='t_boundary')\n",
    "\n",
    "# # model_interior = ModelInterior(model)([x_interior, t_interior])\n",
    "# # model_initial = ModelInitial(model)(x_initial)\n",
    "# # model_boundary = ModelBoundary(model)(t_boundary)\n",
    "\n",
    "# # enforcing wave equation on interior\n",
    "# concat = keras.layers.Concatenate()([x_interior, t_interior])\n",
    "\n",
    "# w_int = model(concat)\n",
    "# dwdx = GradientLayer()([w_int, x_interior])\n",
    "# d2wdx2 = GradientLayer()([dwdx, x_interior])\n",
    "# dwdt = GradientLayer()([w_int, t_interior])\n",
    "# d2wdt2 = GradientLayer()([dwdt, t_interior])\n",
    "\n",
    "# e_int = tf.square(lam*d2wdx2 + d2wdt2)\n",
    "\n",
    "# # enforce initial condition loss\n",
    "# t_initial = tf.zeros(x_initial.shape)\n",
    "# concat = keras.layers.Concatenate()([x_initial, t_initial])\n",
    "\n",
    "# w_init = model(concat)\n",
    "# dwdt = GradientLayer()([w_init, t_initial])\n",
    "\n",
    "# e_init = tf.square(w_init - g1(x_initial)) + tf.square(dwdt - g2(x_initial))\n",
    "\n",
    "# # enforce boundary condition loss\n",
    "# x_boundary0 = tf.zeros(t_boundary.shape)\n",
    "# x_boundary1 = tf.ones(t_boundary.shape)\n",
    "# concat0 = keras.layers.Concatenate()([x_boundary0, t_boundary])\n",
    "# concat1 = keras.layers.Concatenate()([x_boundary1, t_boundary])\n",
    "\n",
    "# w_boundary0 = model(concat0)\n",
    "# w_boundary1 = model(concat1)\n",
    "# e_bound = tf.square(w_boundary0) + tf.square(w_boundary1)\n",
    "\n",
    "# loss = WeightSum(rhof, rho0, rhob)([e_int, e_init, e_bound])\n",
    "# grads = tf.gradients(loss, model.weights)\n",
    "\n",
    "# training_model = keras.Model(\n",
    "#     inputs=[x_interior, t_interior, x_initial, t_boundary],\n",
    "#     outputs=[loss]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20ff7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

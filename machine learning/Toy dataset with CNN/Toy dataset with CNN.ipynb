{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78662359",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "    Toy dataset with CNN\n",
    "    \n",
    "    Author: Daniel Coble\n",
    "    \n",
    "    Status: Work in progress\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c8dd9",
   "metadata": {},
   "source": [
    "In \"Toy datasets and training an MLP\", I created a simple toy dataset with entries of 32x32 black and white pixel grids. Each grid had two lines, and it was the goal of the neural net to predict where the lines would intersect. One can easily see why an MLP might not be the best choice for this type of data. For one thing, the MLP has no sense of left, right, up, and down. It recieves only a flattened vector of the pixel grid, and must intuit our idea of space from the training data. (Imagine all the pixels in the dataset were randomized before being handed to you, and you didn't know how they were randomized. You would find thed task much harder.)\n",
    "\n",
    "Convolutional neural networks do have a sense of direction. The 2D convolutional network trained here applies the same convolution (technically a ) to every element of the 2D grid input to produce another 2D grid. With progressive layers CNNs, the grid will get smaller by the use of __.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32abb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import losses\n",
    "from math import floor\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "def createplot():\n",
    "    length = .3\n",
    "    length_sq = length**2\n",
    "    point = [random.random(), random.random()]\n",
    "    x1 = random.random()\n",
    "    y1 = random.random()\n",
    "    no_space_line_1 = True\n",
    "    while(no_space_line_1):\n",
    "        no_space_line_1 = False\n",
    "        dist1 = (x1-point[0])**2 + (y1-point[1])**2\n",
    "        if(dist1 < length_sq):\n",
    "            no_space_line_1 = True\n",
    "            x1 = random.random()\n",
    "            y1 = random.random()\n",
    "    x2 = random.random()\n",
    "    y2 = random.random()\n",
    "    no_space_line_2 = True\n",
    "    while(no_space_line_2):\n",
    "        no_space_line_2 = False\n",
    "        dist2 = (x2-point[0])**2 + (y2-point[1])**2\n",
    "        if(dist2 < length**2):\n",
    "            no_space_line_2 = True\n",
    "            x2 = random.random()\n",
    "            y2 = random.random()\n",
    "    \n",
    "    dist1 = math.sqrt(dist1)\n",
    "    dist2 = math.sqrt(dist2)\n",
    "    lineseg_1 = np.array([[x1,y1],[x1 + length*(point[0] - x1)/dist1,y1 + length*(point[1] - y1)/dist1]])\n",
    "    lineseg_2 = np.array([[x2,y2],[x2 + length*(point[0] - x2)/dist2,y2 + length*(point[1] - y2)/dist2]])\n",
    "    lineseg_1 = 32*lineseg_1\n",
    "    lineseg_2 = 32*lineseg_2\n",
    "    delta_x = 0.01 * (lineseg_1[1,0] - lineseg_1[0,0])\n",
    "    delta_y = 0.01 * (lineseg_1[1,1] - lineseg_1[0,1])\n",
    "    x1 *= 32\n",
    "    y1 *= 32\n",
    "    \n",
    "    plot = np.zeros(shape=(32,32))\n",
    "    for i in range(100):\n",
    "        x_index = floor(x1 + i*delta_x)\n",
    "        y_index = floor(y1 + i*delta_y)\n",
    "        plot[x_index, y_index] += .0678822\n",
    "    \n",
    "    x2 *= 32\n",
    "    y2 *= 32\n",
    "    delta_x = 0.01 * (lineseg_2[1,0] - lineseg_2[0,0])\n",
    "    delta_y = 0.01 * (lineseg_2[1,1] - lineseg_2[0,1])\n",
    "    \n",
    "    for i in range(100):\n",
    "        x_index = floor(x2 + i*delta_x)\n",
    "        y_index = floor(y2 + i*delta_y)\n",
    "        plot[x_index, y_index] += .0678822\n",
    "    \n",
    "    return (plot, point)\n",
    "    \n",
    "        \n",
    "\n",
    "amount = 100000\n",
    "data = []\n",
    "for i in range(amount):\n",
    "    if((i+1) % (amount//10) == 0):\n",
    "        print(str(round((i+1) / amount * 100)) + \"% finished.\")\n",
    "    data.append(createplot())\n",
    "plots = np.array([data[i][0] for i in range(amount)])\n",
    "points = np.array([data[i][1] for i in range(amount)])\n",
    "\n",
    "train_img, test_img, train_label, test_label = model_selection.train_test_split(plots, points, test_size=.2)\n",
    "\n",
    "for i in range(4):\n",
    "    randint = random.randint(0,2000)\n",
    "    true = test_label[randint] \n",
    "    plt.figure()\n",
    "    plt.imshow(test_img[randint], cmap=mpl.cm.binary, interpolation = 'nearest', origin='lower', extent=[0,1,0,1])\n",
    "    plt.grid(False)\n",
    "    plt.plot(true[1], true[0], marker='x', markersize=12, color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d80df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "\n",
    "#train_img = np.load(\"./dataset/train_img.npy\")\n",
    "#train_label = np.load(\"./dataset/train_label.npy\")\n",
    "#test_img = np.load(\"./dataset/test_img.npy\")\n",
    "#test_label = np.load(\"./dataset/test_label.npy\")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_img, train_label, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61702f9",
   "metadata": {},
   "source": [
    "I said that the advantage of CNNs is that they have very few weights. Compared to a dense layer, a CNN is sparsely connected and uses weight sharing to further reduce the amount of trainable weights. The MLP we trained had 34,978 weights, while this CNN has "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_img,  train_label, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(test_img, test_label, verbose=0)\n",
    "print('Training accuracy:', train_acc)\n",
    "print('Test accuracy: ', test_acc)\n",
    "\n",
    "weight_sum = 0\n",
    "for weights in model.trainable_weights:\n",
    "    weight_sum += np.size(weights)\n",
    "print(\"Amount of weights: \", weight_sum)\n",
    "print(\"Training set size: \", train_img.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

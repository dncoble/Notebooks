{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24784b4b",
   "metadata": {},
   "source": [
    "When I first started working with neural nets, I made this project as an exercise and to get familiar with how they work. The typical introduction to machine learning will use a dataset like MNIST. I think that's fine, and it helps students understand NNs applicability, but I also like the idea of creating our own dataset to train the NN against. Then you have to understand how to process the vectors that are inputs into the NN, and it can be an introduction to preprocessing. \n",
    "\n",
    "In this project, we create a toy dataset which consists of a 30x30 black and white pixel grid (similar to MNIST), but in this dataset each image contains two lines. It will be the goal of the NN to predict where those two lines will intersect. Therefore, the output is a vector of two elements, and the cost function is this point's distance from the correct point.\n",
    "\n",
    "1. Create a dataset on the computer (should have the ability to create as many elements as you want)\n",
    "2. Train an NN on this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b63903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "def createplot():\n",
    "    length = .3\n",
    "    point = np.array([random.random(), random.random()])\n",
    "    \n",
    "    \n",
    "\n",
    "def createplot():\n",
    "    length = .3\n",
    "    point = [random.random(), random.random()]\n",
    "    point_line_1 = [random.random(), random.random()]\n",
    "    point_line_2 = [random.random(), random.random()]\n",
    "    dist_1, dist_2 = 0, 0\n",
    "    no_space_line_1 = True\n",
    "    no_space_line_2 = True\n",
    "    while(no_space_line_1 or no_space_line_2):\n",
    "        no_space_line_1 = False\n",
    "        no_space_line_2 = False\n",
    "        dist_1 = math.sqrt((point_line_1[0]-point[0])**2 + (point_line_1[1]-point[1])**2)\n",
    "        dist_2 = math.sqrt((point_line_2[0]-point[0])**2 + (point_line_2[1]-point[1])**2)\n",
    "        if(dist_1 < length):\n",
    "            no_space_line_1 = True\n",
    "            point_line_1 = [random.random(), random.random()]\n",
    "        if(dist_2 < length):\n",
    "            no_space_line_1 = True\n",
    "            point_line_2 = [random.random(), random.random()]\n",
    "    \n",
    "    \n",
    "    \n",
    "    dist1 = math.sqrt((point_line_1[0]-point[0])**2 + (point_line_1[1]-point[1])**2)\n",
    "    dist2 = math.sqrt((point_line_2[0]-point[0])**2 + (point_line_2[1]-point[1])**2)\n",
    "    \n",
    "    all_points = np.ndarray(shape=(200, 2))\n",
    "    for i in range(100):\n",
    "        all_points[i]=([point_line_1[0]+ i*length/100*(point[0]-point_line_1[0])/dist1, \n",
    "                           point_line_1[1]+ i*length/100*(point[1]-point_line_1[1])/dist1])\n",
    "        all_points[i+100]=([point_line_2[0]+ i*length/100*(point[0]-point_line_2[0])/dist2, \n",
    "                           point_line_2[1]+ i*length/100*(point[1]-point_line_2[1])/dist2])\n",
    "    \n",
    "    plot = np.zeros(shape=(32,32))\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            for k in all_points:\n",
    "                if(k[0]>i/32 and k[0]<(i+1)/32 and k[1]>j/32 and k[1]<(j+1)/32):\n",
    "                    plot[i,j] += .0678822\n",
    "    \n",
    "    return (plot, point)\n",
    "\n",
    "amount = 10000\n",
    "data = [createplot() for i in range(amount)]\n",
    "plots = [data[i][0] for i in range(amount)]\n",
    "points = [data[i][1] for i in range(amount)]\n",
    "\n",
    "train_img = plots[0:8000]\n",
    "test_img = plots[8000:]\n",
    "train_label = points[0:8000]\n",
    "test_label = points[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f3eba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'float\\'>\"})'})",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11348/3497227431.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtest_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    982\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 984\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    985\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'float\\'>\"})'})"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_img, train_label, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_img,  test_label, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "randint = random.randint(0,2000)\n",
    "predictions = model.predict(test_img)\n",
    "true = test_label[randint]*32\n",
    "prediction = predictions[randint]*32\n",
    "\n",
    "plot.figure()\n",
    "randint = random.randint(0,2000)\n",
    "plot.imshow(test_img[randint])\n",
    "plot.grid(False)\n",
    "plot.plot([true[0]], [true[1]], marker='o', markersize=3, color=\"red\")\n",
    "plot.plot([prediction[0]], [prediction[1]], marker='o', markersize=3, color=\"blue\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914775f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
